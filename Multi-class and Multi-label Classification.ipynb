{"cells":[{"metadata":{"ExecuteTime":{"end_time":"2018-07-16T22:26:47.004998Z","start_time":"2018-07-16T22:26:47.001600Z"},"trusted":true},"cell_type":"code","source":"# import libraries\nimport pandas as pd\nimport numpy as np\nimport scipy\nfrom collections import OrderedDict\nfrom sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\nfrom sklearn.svm import SVC, LinearSVC\nfrom imblearn.over_sampling import SMOTE\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":20,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We will work on Anuran Calls (MFCCs) Data Set which can be found here: https://archive.ics.uci.edu/ml/datasets/Anuran+Calls+%28MFCCs)."},{"metadata":{"ExecuteTime":{"end_time":"2018-07-16T22:26:48.106364Z","start_time":"2018-07-16T22:26:48.043999Z"},"trusted":true},"cell_type":"code","source":"dataset = pd.read_csv('../input/Frogs_MFCCs.csv')\ndataset = dataset.drop(['RecordID'], axis = 1)\ncols_to_transform = ['Family','Genus', 'Species']\nLabels = dataset[cols_to_transform].astype('category')\nLabels = Labels[cols_to_transform].apply(lambda x: x.cat.codes)\nFeatures = dataset.iloc[:,0:22]\n\n#split data into training set and test set with training set being 70% of the data\nx_train, x_test, y_train, y_test = train_test_split(Features, Labels, train_size = 0.7, test_size = 0.3)\ny_train1 = y_train['Family']\ny_train2 = y_train['Genus']\ny_train3 = y_train['Species']","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.groupby('Family',axis=0).count()","execution_count":22,"outputs":[{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"                 MFCCs_ 1  MFCCs_ 2  MFCCs_ 3   ...     MFCCs_22  Genus  Species\nFamily                                          ...                             \nBufonidae              68        68        68   ...           68     68       68\nDendrobatidae         542       542       542   ...          542    542      542\nHylidae              2165      2165      2165   ...         2165   2165     2165\nLeptodactylidae      4420      4420      4420   ...         4420   4420     4420\n\n[4 rows x 24 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MFCCs_ 1</th>\n      <th>MFCCs_ 2</th>\n      <th>MFCCs_ 3</th>\n      <th>MFCCs_ 4</th>\n      <th>MFCCs_ 5</th>\n      <th>MFCCs_ 6</th>\n      <th>MFCCs_ 7</th>\n      <th>MFCCs_ 8</th>\n      <th>MFCCs_ 9</th>\n      <th>MFCCs_10</th>\n      <th>MFCCs_11</th>\n      <th>MFCCs_12</th>\n      <th>MFCCs_13</th>\n      <th>MFCCs_14</th>\n      <th>MFCCs_15</th>\n      <th>MFCCs_16</th>\n      <th>MFCCs_17</th>\n      <th>MFCCs_18</th>\n      <th>MFCCs_19</th>\n      <th>MFCCs_20</th>\n      <th>MFCCs_21</th>\n      <th>MFCCs_22</th>\n      <th>Genus</th>\n      <th>Species</th>\n    </tr>\n    <tr>\n      <th>Family</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Bufonidae</th>\n      <td>68</td>\n      <td>68</td>\n      <td>68</td>\n      <td>68</td>\n      <td>68</td>\n      <td>68</td>\n      <td>68</td>\n      <td>68</td>\n      <td>68</td>\n      <td>68</td>\n      <td>68</td>\n      <td>68</td>\n      <td>68</td>\n      <td>68</td>\n      <td>68</td>\n      <td>68</td>\n      <td>68</td>\n      <td>68</td>\n      <td>68</td>\n      <td>68</td>\n      <td>68</td>\n      <td>68</td>\n      <td>68</td>\n      <td>68</td>\n    </tr>\n    <tr>\n      <th>Dendrobatidae</th>\n      <td>542</td>\n      <td>542</td>\n      <td>542</td>\n      <td>542</td>\n      <td>542</td>\n      <td>542</td>\n      <td>542</td>\n      <td>542</td>\n      <td>542</td>\n      <td>542</td>\n      <td>542</td>\n      <td>542</td>\n      <td>542</td>\n      <td>542</td>\n      <td>542</td>\n      <td>542</td>\n      <td>542</td>\n      <td>542</td>\n      <td>542</td>\n      <td>542</td>\n      <td>542</td>\n      <td>542</td>\n      <td>542</td>\n      <td>542</td>\n    </tr>\n    <tr>\n      <th>Hylidae</th>\n      <td>2165</td>\n      <td>2165</td>\n      <td>2165</td>\n      <td>2165</td>\n      <td>2165</td>\n      <td>2165</td>\n      <td>2165</td>\n      <td>2165</td>\n      <td>2165</td>\n      <td>2165</td>\n      <td>2165</td>\n      <td>2165</td>\n      <td>2165</td>\n      <td>2165</td>\n      <td>2165</td>\n      <td>2165</td>\n      <td>2165</td>\n      <td>2165</td>\n      <td>2165</td>\n      <td>2165</td>\n      <td>2165</td>\n      <td>2165</td>\n      <td>2165</td>\n      <td>2165</td>\n    </tr>\n    <tr>\n      <th>Leptodactylidae</th>\n      <td>4420</td>\n      <td>4420</td>\n      <td>4420</td>\n      <td>4420</td>\n      <td>4420</td>\n      <td>4420</td>\n      <td>4420</td>\n      <td>4420</td>\n      <td>4420</td>\n      <td>4420</td>\n      <td>4420</td>\n      <td>4420</td>\n      <td>4420</td>\n      <td>4420</td>\n      <td>4420</td>\n      <td>4420</td>\n      <td>4420</td>\n      <td>4420</td>\n      <td>4420</td>\n      <td>4420</td>\n      <td>4420</td>\n      <td>4420</td>\n      <td>4420</td>\n      <td>4420</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"ExecuteTime":{"end_time":"2018-07-16T22:30:11.093211Z","start_time":"2018-07-16T22:27:05.176488Z"},"trusted":true},"cell_type":"code","source":"#initialize hyper parameters\nC_range = np.logspace(-3, 6, 10) \ngamma_range = np.arange(0.1, 2.1, 0.1) \nparam_grid = dict(gamma=gamma_range, C=C_range)\n\n#perform cross validation on hyper parameters for each label using gaussian kernel svm \ngaussian_grid1 = RandomizedSearchCV(SVC(), param_distributions =param_grid, cv=10)\ngaussian_grid2 = RandomizedSearchCV(SVC(), param_distributions =param_grid, cv=10)\ngaussian_grid3 = RandomizedSearchCV(SVC(), param_distributions =param_grid, cv=10)\ngaussian_grid1.fit(x_train, y_train1)\ngaussian_grid2.fit(x_train, y_train2)\ngaussian_grid3.fit(x_train, y_train3)\n\nprint(\"The best parameters for 1st classifier with gaussian kernel svm are %s with accuracy score of %0.2f\"\n      % (gaussian_grid1.best_params_, gaussian_grid1.best_score_))\n\nprint(\"The best parameters for 2nd classifier with gaussian kernel svm are %s with accuracy score of %0.2f\"\n      % (gaussian_grid2.best_params_, gaussian_grid2.best_score_))\n\nprint(\"The best parameters for 3rd classifier with gaussian kernel svm are %s with accuracy score of %0.2f\"\n      % (gaussian_grid3.best_params_, gaussian_grid3.best_score_))","execution_count":23,"outputs":[{"output_type":"stream","text":"The best parameters for 1st classifier with gaussian kernel svm are {'gamma': 1.3000000000000003, 'C': 1000.0} with accuracy score of 0.99\nThe best parameters for 2nd classifier with gaussian kernel svm are {'gamma': 1.8000000000000003, 'C': 1000000.0} with accuracy score of 0.99\nThe best parameters for 3rd classifier with gaussian kernel svm are {'gamma': 1.6, 'C': 10000.0} with accuracy score of 0.99\n","name":"stdout"}]},{"metadata":{"ExecuteTime":{"end_time":"2018-07-16T22:31:07.898444Z","start_time":"2018-07-16T22:31:07.151032Z"},"trusted":true},"cell_type":"code","source":"#using best parameter values found above perform perdiction on each of the 3 labels\nclf = SVC(C=gaussian_grid1.best_params_['C'], gamma=gaussian_grid1.best_params_['gamma'])\nclf.fit(x_train, y_train1)\ny_pred1 = clf.predict(x_test)\n\nclf = SVC(C=gaussian_grid2.best_params_['C'], gamma=gaussian_grid2.best_params_['gamma'])\nclf.fit(x_train, y_train2)\ny_pred2 = clf.predict(x_test)\n\nclf = SVC(C=gaussian_grid3.best_params_['C'], gamma=gaussian_grid3.best_params_['gamma'])\nclf.fit(x_train, y_train3)\ny_pred3 = clf.predict(x_test)\n\ndata = OrderedDict([('Family', y_pred1), ('Genus', y_pred2), ('Species',\n                                                              y_pred3)])\ngaussian_y_pred = pd.DataFrame.from_dict(data)","execution_count":24,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### We will use Exact match and hamming score/ loss methods for evaluating multi-label classification"},{"metadata":{"ExecuteTime":{"end_time":"2018-07-17T01:04:50.617184Z","start_time":"2018-07-17T01:04:50.611054Z"},"trusted":true},"cell_type":"code","source":"def hamming_loss(ytest, ypred):\n    \"\"\"\n    function to calculate hamming score for given test and predicted values\n    \"\"\"\n    hamm_loss = 0\n    for i in range(0, len(ytest)):\n        losscore = 0\n        for j in range(0, 3):\n            if ytest.iloc[i, j] != ypred.iloc[i, j]:\n                losscore += 1\n            losscore = losscore / 3\n            hamm_loss += losscore\n    hamm_loss /=  (len(ytest))\n    return (hamm_loss)\n\ndef exact_match(ytest, ypred):\n    \"\"\"\n    function to calculate exact match for given test and predicted values\n    \"\"\"\n    exactmatch = 0\n    for i in range(len(ypred)):\n        if (ytest.iloc[i, 0] - ypred.iloc[i, 0] == 0\n                and ytest.iloc[i, 1] - ypred.iloc[i, 1] == 0\n                and ytest.iloc[i, 2] - ypred.iloc[i, 2] == 0):\n            exactmatch += 1\n    exactmatch /=(len(ypred))\n    return (exactmatch)","execution_count":25,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2018-07-17T01:04:53.594243Z","start_time":"2018-07-17T01:04:53.313353Z"},"scrolled":true,"trusted":true},"cell_type":"code","source":"#Evaluating the classifier with gaussian kernel\ngaussiansvm_hamm_loss = hamming_loss(y_test, gaussian_y_pred)\nprint('The Hamming loss for gaussian kernel svm: ', gaussiansvm_hamm_loss)\n\ngaussiansvm_exact_score = exact_match(y_test, gaussian_y_pred)\nprint('The exact match for gaussian kernel svm: ', gaussiansvm_exact_score)","execution_count":26,"outputs":[{"output_type":"stream","text":"The Hamming loss for gaussian kernel svm:  0.011064793371416798\nThe exact match for gaussian kernel svm:  0.9870310328855951\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"#### Let's try above with L1-penalized SVMs"},{"metadata":{"ExecuteTime":{"end_time":"2018-07-16T22:47:32.056952Z","start_time":"2018-07-16T22:33:15.152701Z"},"trusted":true},"cell_type":"code","source":"#initialize hyper parameters\nC_range = np.logspace(-3, 6, 10) \nparam_grid = dict(C=C_range)\n\n#perform cross validation on hyper parameters for each label using L1 penalty svm \nclf = LinearSVC(penalty='l1', dual=False)\nlinear_grid1 = RandomizedSearchCV(clf, param_distributions =param_grid, cv=10)\nlinear_grid2 = RandomizedSearchCV(clf, param_distributions =param_grid, cv=10)\nlinear_grid3 = RandomizedSearchCV(clf, param_distributions =param_grid, cv=10)\nlinear_grid1.fit(x_train, y_train1)\nlinear_grid2.fit(x_train, y_train2)\nlinear_grid3.fit(x_train, y_train3)\n\nprint(\"The best parameters for 1st classifier with L1 penalty svm are %s with accuracy score of %0.2f\"\n      % (linear_grid1.best_params_, linear_grid1.best_score_))\n\nprint(\"The best parameters for 2nd classifier with L1 penalty svm are %s with accuracy score of %0.2f\"\n      % (linear_grid2.best_params_, linear_grid2.best_score_))\n\nprint(\"The best parameters for 3rd classifier with L1 penalty svm are %s with accuracy score of %0.2f\"\n      % (linear_grid3.best_params_, linear_grid3.best_score_))","execution_count":27,"outputs":[{"output_type":"stream","text":"The best parameters for 1st classifier with L1 penalty svm are {'C': 10.0} with accuracy score of 0.93\nThe best parameters for 2nd classifier with L1 penalty svm are {'C': 1000000.0} with accuracy score of 0.95\nThe best parameters for 3rd classifier with L1 penalty svm are {'C': 100.0} with accuracy score of 0.96\n","name":"stdout"}]},{"metadata":{"ExecuteTime":{"end_time":"2018-07-16T22:51:21.168567Z","start_time":"2018-07-16T22:51:08.446939Z"},"scrolled":false,"trusted":true},"cell_type":"code","source":"#using best parameter values found above perform perdiction on each of the 3 labels\nlinear_clf = LinearSVC(\n    penalty='l1',\n    dual=False,\n    C=linear_grid3.best_params_['C'],\n)\nlinear_clf.fit(x_train, y_train1)\ny_pred1 = linear_clf.predict(x_test)\n\nlinear_clf = LinearSVC(penalty='l1', dual=False, C=linear_grid2.best_params_['C'])\nlinear_clf.fit(x_train, y_train2)\ny_pred2 = linear_clf.predict(x_test)\n\nlinear_clf = LinearSVC(penalty='l1', dual=False, C=linear_grid3.best_params_['C'])\nlinear_clf.fit(x_train, y_train3)\ny_pred3 = linear_clf.predict(x_test)\n\ndata = OrderedDict([('Family', y_pred1), ('Genus', y_pred2), ('Species',\n                                                              y_pred3)])\nlinear_y_pred = pd.DataFrame.from_dict(data)\n\n\n#Hamming loss\nlinearsvm_hamm_loss = hamming_loss(y_test, linear_y_pred)\nprint('The Hamming loss for svm with L1 penalty: ', linearsvm_hamm_loss)\n\n#Exact match\nlinearsvm_exact_score = exact_match(y_test, linear_y_pred)\nprint('The exact match for svm with L1 penalty: ', linearsvm_exact_score)","execution_count":29,"outputs":[{"output_type":"stream","text":"The Hamming loss for svm with L1 penalty:  0.06450174120391818\nThe exact match for svm with L1 penalty:  0.920796665122742\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"#### As seen from the dataset, there seems to be class imbalance. Let's try to remedy that using SMOTE"},{"metadata":{"ExecuteTime":{"end_time":"2018-07-17T00:27:29.168957Z","start_time":"2018-07-16T22:52:45.526448Z"},"trusted":true},"cell_type":"code","source":"#perform SMOTE\nsvm_smote = SMOTE()\nx_sampled_train1, y_sampled_train1 = svm_smote.fit_sample(x_train, y_train1)\nx_sampled_train2, y_sampled_train2 = svm_smote.fit_sample(x_train, y_train2)\nx_sampled_train3, y_sampled_train3 = svm_smote.fit_sample(x_train, y_train3)\n\n#initialize hyper parameters\nC_range = np.logspace(-3, 6, 10) \nparam_grid = dict(C=C_range)\n\n#perform cross validation on hyper parameters for each label using L1 penalty svm \nclf = LinearSVC(penalty='l1', dual=False)\nsmote_grid1 = RandomizedSearchCV(clf, param_distributions =param_grid, cv=10)\nsmote_grid2 = RandomizedSearchCV(clf, param_distributions =param_grid, cv=10)\nsmote_grid3 = RandomizedSearchCV(clf, param_distributions =param_grid, cv=10)\nsmote_grid1.fit(x_sampled_train1, y_sampled_train1)\nsmote_grid2.fit(x_sampled_train2, y_sampled_train2)\nsmote_grid3.fit(x_sampled_train3, y_sampled_train3)\n\nprint(\"The best parameters for 1st classifier with SMOTE L1 penalty svm are %s with accuracy score of %0.2f\"\n      % (smote_grid1.best_params_, smote_grid1.best_score_))\n\nprint(\"The best parameters for 2nd classifier with SMOTE penalty svm are %s with accuracy score of %0.2f\"\n      % (smote_grid2.best_params_, smote_grid2.best_score_))\n\nprint(\"The best parameters for 3rd classifier with SMOTE penalty svm are %s with accuracy score of %0.2f\"\n      % (smote_grid3.best_params_, smote_grid3.best_score_))","execution_count":30,"outputs":[{"output_type":"stream","text":"The best parameters for 1st classifier with SM OTE L1 penalty svm are {'C': 100.0} with accuracy score of 0.95\nThe best parameters for 2nd classifier with SMOTE penalty svm are {'C': 10.0} with accuracy score of 0.96\nThe best parameters for 3rd classifier with SMOTE penalty svm are {'C': 1000.0} with accuracy score of 0.96\n","name":"stdout"}]},{"metadata":{"ExecuteTime":{"end_time":"2018-07-17T00:29:38.685900Z","start_time":"2018-07-17T00:28:19.897272Z"},"trusted":true},"cell_type":"code","source":"#using best parameter values found above perform perdiction on each of the 3 labels\n\nsmote_clf = LinearSVC(penalty='l1', dual=False, C=smote_grid1.best_params_['C'])\nsmote_clf.fit(x_sampled_train1, y_sampled_train1)\ny_pred1 = smote_clf.predict(x_test)\n\nsmote_clf = LinearSVC(penalty='l1', dual=False, C=smote_grid2.best_params_['C'])\nsmote_clf.fit(x_sampled_train2, y_sampled_train2)\ny_pred2 = smote_clf.predict(x_test)\n\nsmote_clf = LinearSVC(penalty='l1', dual=False, C=smote_grid3.best_params_['C'])\nsmote_clf.fit(x_sampled_train3, y_sampled_train3)\ny_pred3 = smote_clf.predict(x_test)\n\ndata = OrderedDict([('Family', y_pred1), ('Genus', y_pred2), ('Species',\n                                                              y_pred3)])\nsmote_y_pred = pd.DataFrame.from_dict(data)\n\n#Hamming loss\nsmote_hamm_loss = hamming_loss(y_test, smote_y_pred)\nprint('The Hamming loss for svm with smote: ', smote_hamm_loss)\n\n#Exact match\nsmote_exact_score = exact_match(y_test, smote_y_pred)\nprint('The exact match for svm with smote: ',smote_exact_score)","execution_count":31,"outputs":[{"output_type":"stream","text":"The Hamming loss for svm with smote:  0.0882095620400399\nThe exact match for svm with smote:  0.8666049096804076\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"We see that, SVM with gaussian kernel has better exact match or low hamming loss compared to L1 penalized SVM. However on applying SMOTE the exact match reduces or hamming loss increases for L1 penalized SVM"},{"metadata":{},"cell_type":"markdown","source":"#### Let's now try to solve this multi-label classification using Classifier Chain method (For more info - https://www.analyticsvidhya.com/blog/2017/08/introduction-to-multi-label-classification/)"},{"metadata":{"ExecuteTime":{"end_time":"2018-07-17T00:41:19.188447Z","start_time":"2018-07-17T00:30:29.371646Z"},"trusted":true},"cell_type":"code","source":"x_train_cchain1 = x_train\nx_train_cchain2 = pd.concat([x_train, y_train1], axis = 1)\nx_train_cchain3 = pd.concat([x_train, y_train1,y_train2], axis = 1)\n\n#initialize hyper parameters\nC_range = np.logspace(-3, 6, 10) \nparam_grid = dict(C=C_range)\n\n#perform cross validation on hyper parameters for each label using L1 penalty svm \nclf = LinearSVC(penalty='l1', dual=False)\nclassifer_grid1 = RandomizedSearchCV(clf, param_distributions =param_grid, cv=10)\nclassifer_grid2 = RandomizedSearchCV(clf, param_distributions =param_grid, cv=10)\nclassifer_grid3 = RandomizedSearchCV(clf, param_distributions =param_grid, cv=10)\n\nclassifer_grid1.fit(x_train_cchain1, y_train1)\nclassifer_grid2.fit(x_train_cchain2, y_train2)\nclassifer_grid3.fit(x_train_cchain3, y_train3)\n\nprint(\n    \"The best parameter for 1st classifier using classifier chain with L1 Penalty SVM is C: %s with accuracy score of %0.2f\"\n    % (classifer_grid1.best_params_, classifer_grid1.best_score_))\n\nprint(\n    \"The best parameter for 2nd classifier using classifier chain  with L1 Penalty SVM is C: %s with accuracy score of %0.2f\"\n    % (classifer_grid2.best_params_, classifer_grid2.best_score_))\n\nprint(\n    \"The best parameter for 3rd classifier using classifier chain  with L1 Penalty SVM is C: %s with accuracy score of %0.2f\"\n    % (classifer_grid3.best_params_, classifer_grid3.best_score_))","execution_count":32,"outputs":[{"output_type":"stream","text":"The best parameter for 1st classifier using classifier chain with L1 Penalty SVM is C: {'C': 10.0} with accuracy score of 0.94\nThe best parameter for 2nd classifier using classifier chain  with L1 Penalty SVM is C: {'C': 10.0} with accuracy score of 0.98\nThe best parameter for 3rd classifier using classifier chain  with L1 Penalty SVM is C: {'C': 1000.0} with accuracy score of 0.99\n","name":"stdout"}]},{"metadata":{"ExecuteTime":{"end_time":"2018-07-17T00:44:44.753131Z","start_time":"2018-07-17T00:44:35.208269Z"},"trusted":true},"cell_type":"code","source":"y_test1 = y_test['Family']\ny_test2 = y_test['Genus']\ny_test3 = y_test['Species']\n\n#creating feature set for classifier chain\nx_test_cchain1 = x_test\nx_test_cchain2 = pd.concat([x_test, y_test1], axis = 1, ignore_index=False)\nx_test_cchain3 = pd.concat([x_test, y_test1,y_test2], axis = 1, ignore_index=False)\n\ncchain_clf = LinearSVC(\n    penalty='l1',\n    dual=False,\n    C=classifer_grid1.best_params_['C'],\n)\ncchain_clf.fit(x_train_cchain1, y_train1)\ny_pred1 = cchain_clf.predict(x_test_cchain1)\n\ncchain_clf = LinearSVC(penalty='l1', dual=False, C=classifer_grid2.best_params_['C'])\ncchain_clf.fit(x_train_cchain2, y_train2)\ny_pred2 = cchain_clf.predict(x_test_cchain2)\n\ncchain_clf = LinearSVC(penalty='l1', dual=False, C=classifer_grid3.best_params_['C'])\ncchain_clf.fit(x_train_cchain3, y_train3)\ny_pred3 = cchain_clf.predict(x_test_cchain3)\n\ndata = OrderedDict([('Family', y_pred1), ('Genus', y_pred2), ('Species',\n                                                              y_pred3)])\ncchain_y_pred = pd.DataFrame.from_dict(data)\n\n\n#Hamming loss\ncchain_hamm_loss = hamming_loss(y_test, cchain_y_pred)\nprint('The Hamming loss for classifier chain with L1 penalty SVM: ', cchain_hamm_loss)\n\n#Exact match\ncchain_exact_score = exact_match(y_test, cchain_y_pred)\nprint('The exact match for classifier chain with L1 penalty SVM: ', cchain_exact_score)","execution_count":33,"outputs":[{"output_type":"stream","text":"The Hamming loss for classifier chain with L1 penalty SVM:  0.040656682620554864\nThe exact match for classifier chain with L1 penalty SVM:  0.9286706808707735\n","name":"stdout"}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"nbformat":4,"nbformat_minor":1}